predict future agent motion dynamic environment activity forecastinginverse reinforcement learningmultiple object track understanding activity people monitor environment topic active research motivate by application require contextawareness infer future agent motion useful not only improve track accuracy but also plan an interactive motion task despite rapid advance area activity forecast many stateoftheart method still cumbersome use realistic robot this due requirement have good semantic scene map label well assumption make regard possible goal type motion many emerge application require robot with modest sensory computational ability robustly perform such activity forecast high density dynamic environment address this by combine novel multicamera track method efficient multiresolution representation state standard inverse reinforcement learn irl technique demonstrate performance that good than stateoftheart literature this framework irl method use agent trajectory from distribute tracker estimate reward function within markov decision process mdp model this reward function then use estimate agent motion future novel task instance present empirical experiment use data gather our own lab external corpus virat base which find that our algorithm not only efficiently implementable resource constrain platform but also competitive term accuracy with stateoftheart alternative eg good than result report