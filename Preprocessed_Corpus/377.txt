direct multiclass boost use base classifier posterior probability estimate machine learningboostingmarginmulticlass classification present new multiclass boosting algorithm call adaboostbg like original freund shapires adaboost algorithm it aggregate tree but instead use their misclassification error it take into account margin observation which may see confidence measure their prediction rather then their correctness prove efficiency our algorithm by simulation compare it similar approach know minimize global margin final classifier