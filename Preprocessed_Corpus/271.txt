bayesian unification gradient banditbased learn accelerate global optimisation global optimizationmultiarmed banditsonline learningmultistrategy learn bandit base optimisation scheme remarkable advantage over gradient base approach due their global perspective which eliminate danger get stuck local optimum however continuous optimisation problem or problem with large number action bandit base approach hinder by slow learn gradient base approach other hand navigate quickly highdimensional continuous space through local optimisation follow gradient fine grain step however apart from be susceptible local optimum these scheme also less suited online learn due their reliance extensive trialanderror before optimum identify contrast bandit algorithms seek identify optimal action global optimum few step possible this paper propose bayesian approach that unifies above two distinct paradigms one single framework with aim combine their advantage heart our approach find stochastic linear approximation function optimise where both gradient value function explicitly capture this model allow u learn from both noisy function gradient observation well predict these property across action space support optimisation far propose an accompany bandit drive exploration scheme that use bayesian credible bound trade off exploration against exploitation our empirical result demonstrate that by unify bandit gradient base learn one obtain consistently improve performance across wide spectrum problem environment furthermore even when gradient feedback unavailable flexibility our model include gradient prediction still allow u outperform compete approach although with small margin