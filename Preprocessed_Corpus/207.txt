resamplingbased variable selection with lasso p n partially linear model feature selectionvariable selectionbig datahighdimensional datalasso regressionnonlinearity linear model regression function widely use perhaps most case highly unrealistic simplify assumption when propose consistent variable selection method large highlydimensional datasets this paper study what happen from theoretical point view when variable selection method assume linear regression function underlie groundtruth model compose linear nonlinear term that most partially linear demonstrate consistency lasso method when model partially linear however note that algorithm tend increase even more number select false positive partially linear model when give few training sample that usually because value small group sample happen explain variation come from nonlinear part response function noise use linear combination wrong predictor demonstrate theoretically that false positive likely select by lasso method due small proportion sample which happen explain some variation response variable show that this property imply that if run lasso several slightly small size data replication sample without replacement intersect result likely reduce number false positive without lose already select true positive propose novel consistent variable selection algorithm base this property show it outperform other variable selection method synthetic datasets linear partially linear model datasets from uci machine learn repository