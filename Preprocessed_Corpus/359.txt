google cloud vision api not robust noise google cloud vision apimachine learningimage noiseadversarial machine learn google recently introduce cloud vision api image analysis accord demonstration website api quickly classifies image into thousand category detects individual object face within image find read print word contain within image it also use detect different type inappropriate content from adult violent content this paper evaluate robustness google cloud vision api input perturbation particular show that by add sufficient noise image api generate completely different output noisy image while human observer would perceive it original content show that attack consistently successful by perform extensive experiment different image type include natural image image contain face image with texts instance use image from imagenet dataset find that add an average impulse noise enough deceive api our finding indicate vulnerability api adversarial environment example an adversary bypass an image filtering system by add noise inappropriate image then show that when noise filter apply input image api generates mostly same output restore image original image this observation suggest that cloud vision api readily benefit from noise filter without need update image analysis algorithm