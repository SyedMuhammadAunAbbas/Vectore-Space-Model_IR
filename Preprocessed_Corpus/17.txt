state abstraction reinforcement learning by eliminate useless dimension reinforcement learn state abstraction intelligent agent complexity reduction qlearning other linear dynamic learn algorithm subject bellman curse dimensionality any realistic learning problem this paper introduce framework satisfice state abstraction one that reduce state dimensionality improve convergence reduce computational memory resource by eliminate useless state dimension statistical parameter that dependent state qvalues identify relevance give state space task space allow state element that contribute least task learn discard empirical result apply state abstraction canonical singleagent path planning task more difficult multiagent forage problem demonstrate utility propose method improve learn convergence performance resourceconstrained learn problem