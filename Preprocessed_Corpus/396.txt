new framework fine tune deep network deep learningdeep neural networksfine tuningdrop out techniquegain parameter drop out technique very often train deep neural network involve two learning phase unsupervised pretraining supervise fine tuning unsupervised pretraining use learn parameter deep neural network while supervised fine tune improves upon what be learnt pretraining stage predominant algorithm that use supervise fine tune deep neural network standard backpropagation algorithm however field shallow neural network number modification backpropagation algorithm be propose that improved performance train model this paper propose hybrid approach that integrate gain parameter base backpropagation algorithm dropout technique evaluate it effectiveness fine tune deep neural network three benchmark datasets result indicate that propose hybrid approach performs well fine tune than backpropagation algorithm alone